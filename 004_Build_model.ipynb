{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nueral network comprices of layers/modules that perform operations on data.\n",
        "\n",
        "the [torch.nn](https://pytorch.org/docs/stable/nn.html) provides all the building blocks you need to build your own neural network"
      ],
      "metadata": {
        "id": "YDfdqsjXOC32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network to classify images in the FashionMNIST dataset.\n"
      ],
      "metadata": {
        "id": "YXtYG7IqQnI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "w0oWYmUyQI0o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get a device for training\n"
      ],
      "metadata": {
        "id": "dRxrC9gkQkRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to be able to train a model on an accelerator such as CUDA, MPS, MTIA or XPU"
      ],
      "metadata": {
        "id": "jqI9bSn3Q1ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrIilzRcRiNN",
        "outputId": "75fddd0a-cf29-4304-c8b3-8d4d770c6439"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pfmyLbPR1Ll",
        "outputId": "318df95b-08f3-43b1-eb3a-c629952ebf03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 13 11:36:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L #list available nvidia devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY-8NBlROe0",
        "outputId": "d35274cd-f502-4ba1-c13a-1c174a9b2778"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-8d249efe-d52b-788e-87b1-48041d3e09b1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the class"
      ],
      "metadata": {
        "id": "GzNPRN7uSxx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): #sub class inherits from the nn.Module super class\n",
        "  def __init__(self):\n",
        "    super().__init__() #calls the nn.Module constructor\n",
        "    self.flatten =nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "dN0pbmZhTIuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fG_zCN2g2mn",
        "outputId": "c6b29f6a-e1fa-49a8-ddbb-d8eabd9d9b9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the model we pass in the input data. This executes the models `forward`"
      ],
      "metadata": {
        "id": "6dk1b3hLiZ-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predictied values for each class, and dim=1 corresponding to the individual values of each output.\n",
        "\n",
        "we get the prediction probabilities by passing it throught an instance of the `nn.softmax` module"
      ],
      "metadata": {
        "id": "yJnfTJ5ei4gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device = device )\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU9pM_uHjukG",
        "outputId": "fc798d45-8bb6-48af-e546-f679e976fed2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2673, 0.4616, 0.6439, 0.1135, 0.3129, 0.9808, 0.6728, 0.2944,\n",
              "          0.1140, 0.1431, 0.6632, 0.6748, 0.4022, 0.7723, 0.6514, 0.9899,\n",
              "          0.4485, 0.6280, 0.7989, 0.4605, 0.7856, 0.9924, 0.5583, 0.4990,\n",
              "          0.9674, 0.5661, 0.1834, 0.3078],\n",
              "         [0.4977, 0.4825, 0.4009, 0.9072, 0.1756, 0.7436, 0.8044, 0.3969,\n",
              "          0.2072, 0.4688, 0.2921, 0.4764, 0.4385, 0.3407, 0.9944, 0.2457,\n",
              "          0.1149, 0.3104, 0.5594, 0.1053, 0.7252, 0.1867, 0.1969, 0.6313,\n",
              "          0.7503, 0.8884, 0.9234, 0.5925],\n",
              "         [0.7620, 0.4384, 0.7022, 0.3244, 0.4776, 0.6039, 0.3639, 0.6401,\n",
              "          0.1652, 0.2680, 0.9155, 0.5096, 0.5303, 0.9118, 0.2061, 0.0977,\n",
              "          0.7700, 0.9031, 0.6211, 0.0383, 0.7915, 0.5787, 0.4181, 0.3859,\n",
              "          0.2295, 0.0854, 0.2746, 0.0665],\n",
              "         [0.1093, 0.3264, 0.5218, 0.6346, 0.2258, 0.3193, 0.7571, 0.8046,\n",
              "          0.1708, 0.0653, 0.7936, 0.2982, 0.7171, 0.1653, 0.3651, 0.4892,\n",
              "          0.3586, 0.0861, 0.1788, 0.7454, 0.5267, 0.4438, 0.6904, 0.2376,\n",
              "          0.1411, 0.2456, 0.0745, 0.4934],\n",
              "         [0.8330, 0.5506, 0.1566, 0.0668, 0.4993, 0.3597, 0.8871, 0.4314,\n",
              "          0.2433, 0.3661, 0.5947, 0.3333, 0.3708, 0.9769, 0.8113, 0.0810,\n",
              "          0.2277, 0.5158, 0.9226, 0.8990, 0.0872, 0.0789, 0.2712, 0.5884,\n",
              "          0.7322, 0.4145, 0.9033, 0.3166],\n",
              "         [0.0185, 0.3918, 0.1202, 0.2069, 0.2339, 0.1545, 0.8555, 0.9024,\n",
              "          0.3920, 0.9939, 0.0605, 0.5951, 0.1092, 0.4580, 0.7745, 0.2853,\n",
              "          0.5864, 0.5154, 0.6080, 0.5263, 0.5247, 0.1862, 0.5097, 0.9628,\n",
              "          0.6310, 0.2001, 0.2790, 0.4946],\n",
              "         [0.9602, 0.7984, 0.0761, 0.5875, 0.2715, 0.7728, 0.6162, 0.3401,\n",
              "          0.0615, 0.2922, 0.9001, 0.7092, 0.4470, 0.7887, 0.7261, 0.4762,\n",
              "          0.4131, 0.5768, 0.4663, 0.4672, 0.8264, 0.3550, 0.2165, 0.7376,\n",
              "          0.5430, 0.5909, 0.8582, 0.5672],\n",
              "         [0.2454, 0.2813, 0.8246, 0.1430, 0.3489, 0.7190, 0.4113, 0.7748,\n",
              "          0.7530, 0.1914, 0.0818, 0.7181, 0.3096, 0.2767, 0.0279, 0.1832,\n",
              "          0.8316, 0.9339, 0.2335, 0.6824, 0.2577, 0.1311, 0.9167, 0.9022,\n",
              "          0.5463, 0.6527, 0.3359, 0.7602],\n",
              "         [0.5593, 0.5627, 0.4469, 0.5262, 0.3431, 0.6575, 0.0041, 0.5607,\n",
              "          0.3972, 0.9708, 0.0860, 0.1923, 0.1370, 0.4671, 0.1279, 0.4830,\n",
              "          0.5816, 0.6512, 0.4149, 0.5113, 0.8210, 0.4237, 0.6072, 0.6699,\n",
              "          0.5130, 0.6483, 0.2074, 0.4257],\n",
              "         [0.1742, 0.9386, 0.6549, 0.6548, 0.3452, 0.3405, 0.5391, 0.2326,\n",
              "          0.5655, 0.7930, 0.0971, 0.0297, 0.4584, 0.1754, 0.7850, 0.1829,\n",
              "          0.0031, 0.1677, 0.0982, 0.8571, 0.1366, 0.5268, 0.1608, 0.7924,\n",
              "          0.4309, 0.2318, 0.6415, 0.7520],\n",
              "         [0.7955, 0.3049, 0.3011, 0.4048, 0.8529, 0.1557, 0.5838, 0.3952,\n",
              "          0.3041, 0.1152, 0.5062, 0.9066, 0.8780, 0.4250, 0.0635, 0.1104,\n",
              "          0.1463, 0.9458, 0.2037, 0.9124, 0.1753, 0.3612, 0.6946, 0.8576,\n",
              "          0.3570, 0.2209, 0.9026, 0.9680],\n",
              "         [0.7778, 0.0909, 0.3345, 0.3460, 0.9795, 0.4540, 0.7256, 0.8581,\n",
              "          0.8001, 0.0994, 0.8996, 0.3930, 0.9575, 0.4996, 0.6487, 0.5407,\n",
              "          0.7709, 0.6933, 0.8743, 0.6565, 0.3726, 0.0392, 0.2531, 0.0514,\n",
              "          0.3267, 0.7380, 0.7592, 0.4700],\n",
              "         [0.0782, 0.9537, 0.6965, 0.6312, 0.3646, 0.3473, 0.4754, 0.6516,\n",
              "          0.6669, 0.5621, 0.9844, 0.9748, 0.8667, 0.8282, 0.5454, 0.8222,\n",
              "          0.7518, 0.1267, 0.1607, 0.1233, 0.0645, 0.0710, 0.1986, 0.0125,\n",
              "          0.2324, 0.7266, 0.5323, 0.8352],\n",
              "         [0.8340, 0.4505, 0.4265, 0.8438, 0.7148, 0.6048, 0.3787, 0.7400,\n",
              "          0.5999, 0.4449, 0.1987, 0.7721, 0.9537, 0.8028, 0.7538, 0.0198,\n",
              "          0.8810, 0.2261, 0.0238, 0.8511, 0.7839, 0.2581, 0.2587, 0.5160,\n",
              "          0.6743, 0.0802, 0.6421, 0.3202],\n",
              "         [0.2467, 0.4832, 0.2207, 0.2829, 0.0738, 0.4478, 0.9104, 0.8427,\n",
              "          0.9122, 0.2475, 0.4590, 0.0471, 0.9732, 0.6352, 0.2397, 0.3506,\n",
              "          0.3247, 0.0691, 0.4595, 0.2231, 0.3911, 0.3286, 0.5879, 0.9736,\n",
              "          0.6149, 0.2690, 0.9694, 0.7356],\n",
              "         [0.3433, 0.7212, 0.5092, 0.4788, 0.2380, 0.1547, 0.8329, 0.6533,\n",
              "          0.2280, 0.9674, 0.3357, 0.2810, 0.4761, 0.5598, 0.9837, 0.2174,\n",
              "          0.4603, 0.0408, 0.6137, 0.0908, 0.4390, 0.8935, 0.5200, 0.5587,\n",
              "          0.0166, 0.6966, 0.4161, 0.8051],\n",
              "         [0.2546, 0.4828, 0.7128, 0.2064, 0.6182, 0.2412, 0.7836, 0.0340,\n",
              "          0.1564, 0.7833, 0.7431, 0.4558, 0.7202, 0.2292, 0.7135, 0.6920,\n",
              "          0.6296, 0.5889, 0.1424, 0.6224, 0.8864, 0.2820, 0.9344, 0.8456,\n",
              "          0.3715, 0.6174, 0.7427, 0.9128],\n",
              "         [0.8410, 0.2394, 0.4589, 0.4657, 0.1722, 0.1164, 0.1251, 0.3139,\n",
              "          0.8116, 0.2342, 0.3645, 0.5683, 0.7834, 0.5950, 0.2418, 0.3662,\n",
              "          0.1743, 0.9081, 0.8070, 0.1272, 0.8133, 0.2760, 0.0340, 0.2390,\n",
              "          0.2058, 0.5897, 0.1132, 0.7561],\n",
              "         [0.9711, 0.8523, 0.9472, 0.7034, 0.3708, 0.4720, 0.4958, 0.3455,\n",
              "          0.9918, 0.9720, 0.8047, 0.0650, 0.1852, 0.9955, 0.6510, 0.1845,\n",
              "          0.4490, 0.0897, 0.1403, 0.5765, 0.6998, 0.8630, 0.6141, 0.8469,\n",
              "          0.4224, 0.5907, 0.9759, 0.5383],\n",
              "         [0.3578, 0.3849, 0.3474, 0.9421, 0.7527, 0.0854, 0.7999, 0.8575,\n",
              "          0.5678, 0.8690, 0.5581, 0.8359, 0.5436, 0.3439, 0.9364, 0.7546,\n",
              "          0.8495, 0.7617, 0.9926, 0.4971, 0.6194, 0.0984, 0.0282, 0.5019,\n",
              "          0.3827, 0.1384, 0.7649, 0.7942],\n",
              "         [0.5672, 0.1979, 0.1147, 0.0868, 0.8142, 0.6712, 0.4256, 0.7660,\n",
              "          0.0901, 0.6685, 0.3173, 0.6218, 0.8848, 0.1092, 0.8294, 0.8115,\n",
              "          0.3241, 0.2623, 0.6688, 0.7442, 0.4860, 0.1320, 0.7082, 0.3262,\n",
              "          0.1892, 0.5073, 0.9213, 0.8639],\n",
              "         [0.7312, 0.2629, 0.4641, 0.6861, 0.1143, 0.6918, 0.4750, 0.5128,\n",
              "          0.2520, 0.4406, 0.2060, 0.3297, 0.1480, 0.6079, 0.6277, 0.2532,\n",
              "          0.3018, 0.3560, 0.8230, 0.7787, 0.9885, 0.7162, 0.9644, 0.1976,\n",
              "          0.8980, 0.3240, 0.3562, 0.5795],\n",
              "         [0.0719, 0.2021, 0.4116, 0.2155, 0.5489, 0.4439, 0.3224, 0.0797,\n",
              "          0.3400, 0.6894, 0.7367, 0.2284, 0.1131, 0.0316, 0.3395, 0.7528,\n",
              "          0.9657, 0.7878, 0.0843, 0.9190, 0.0826, 0.8953, 0.3802, 0.3976,\n",
              "          0.8570, 0.4062, 0.5085, 0.1015],\n",
              "         [0.8245, 0.5378, 0.6392, 0.7792, 0.4455, 0.6969, 0.5277, 0.4165,\n",
              "          0.2054, 0.9000, 0.1530, 0.0984, 0.2220, 0.2998, 0.6717, 0.1496,\n",
              "          0.6323, 0.5873, 0.9974, 0.4318, 0.5259, 0.5116, 0.7494, 0.9818,\n",
              "          0.2006, 0.9001, 0.2415, 0.4941],\n",
              "         [0.8380, 0.6324, 0.0228, 0.7950, 0.5712, 0.9372, 0.1829, 0.6099,\n",
              "          0.5357, 0.3669, 0.3643, 0.4791, 0.5621, 0.6399, 0.1527, 0.5864,\n",
              "          0.6391, 0.6404, 0.4908, 0.9757, 0.1060, 0.5106, 0.6811, 0.1078,\n",
              "          0.7258, 0.1687, 0.8741, 0.0841],\n",
              "         [0.6251, 0.5649, 0.8660, 0.9583, 0.3046, 0.8950, 0.2081, 0.0525,\n",
              "          0.7627, 0.5774, 0.6473, 0.1436, 0.8961, 0.3977, 0.9745, 0.4345,\n",
              "          0.6878, 0.4757, 0.2568, 0.7045, 0.2595, 0.5841, 0.9382, 0.4292,\n",
              "          0.3914, 0.2799, 0.2029, 0.9942],\n",
              "         [0.8810, 0.8358, 0.7216, 0.3786, 0.9954, 0.2476, 0.8028, 0.0650,\n",
              "          0.4521, 0.4467, 0.1178, 0.8433, 0.3927, 0.0577, 0.1691, 0.6373,\n",
              "          0.2787, 0.9502, 0.8877, 0.4586, 0.0665, 0.4662, 0.0024, 0.0606,\n",
              "          0.5338, 0.0755, 0.5147, 0.8671],\n",
              "         [0.1337, 0.8662, 0.5401, 0.9759, 0.3337, 0.5978, 0.7261, 0.5017,\n",
              "          0.4680, 0.2880, 0.7019, 0.0539, 0.0379, 0.4372, 0.5419, 0.3660,\n",
              "          0.8693, 0.1179, 0.4097, 0.2335, 0.2448, 0.6795, 0.5809, 0.9158,\n",
              "          0.6372, 0.0501, 0.8681, 0.8479]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(X)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW4DRMA9lVrg",
        "outputId": "7280359e-566c-430d-f280-789e73423fa8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0668,  0.0271, -0.0193, -0.0773, -0.0405, -0.0205,  0.0092, -0.0075,\n",
              "          0.1733,  0.0580]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "pred_probab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVVP6wgwlg8D",
        "outputId": "bc1e2087-e714-4714-ae94-4d9694e04bba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1049, 0.1008, 0.0962, 0.0908, 0.0942, 0.0961, 0.0990, 0.0974, 0.1167,\n",
              "         0.1040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY8AsktWlv2p",
        "outputId": "787f087a-d02d-4850-c3d8-bed967198162"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([8], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Layers"
      ],
      "metadata": {
        "id": "iB6oyEHel5Om"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "breaking it down -  Take a sample minibatch of 3 images of size 28 X 28 and see what happens to it as we pass it through the network\n"
      ],
      "metadata": {
        "id": "AUjEQ6Qil-jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n_3eFinnVTY",
        "outputId": "51d8c063-476a-4320-d1ae-f85ca39692ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Flatten"
      ],
      "metadata": {
        "id": "UB621_oxnfUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the `nn.Flatten` layer to convert each 2D 28x28 image into a contigous array of 784 pixel values (the minibatch dimension (at dim=0) is maintained"
      ],
      "metadata": {
        "id": "vXCgdAVBnvim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz3wcEfUnsVm",
        "outputId": "083d6a9c-c507-46aa-a833-aa1448ed2a83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Linear"
      ],
      "metadata": {
        "id": "-Apu2ydOnuwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Linear` applies a linear transformation on the input using its stored weights and biases"
      ],
      "metadata": {
        "id": "fMlHoz5pob2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "layer1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5glfwnYoojD",
        "outputId": "88fcedfd-788a-44ed-d3f8-c509ca6fde55"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=20, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = layer1(flat_image)\n",
        "hidden1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05spVsHKo2JK",
        "outputId": "088e724c-d652-497d-a9c3-b53e86d00138"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2155, -0.4049, -0.8427,  0.1457, -0.0643, -0.4941, -0.4382, -0.1710,\n",
              "         -0.1029, -0.2099, -0.1976, -0.2963,  0.4958,  0.0162, -0.7350, -0.5259,\n",
              "          0.1827, -0.0915, -0.2880, -0.1483],\n",
              "        [ 0.2453, -0.3701, -0.7320,  0.3557,  0.1142, -0.1105, -0.5984, -0.2136,\n",
              "         -0.4932, -0.3136, -0.0386, -0.0660,  0.4938,  0.4970, -0.7241, -0.6247,\n",
              "         -0.0164, -0.1783, -0.4323,  0.0151],\n",
              "        [ 0.3137, -0.6424, -0.5849,  0.1244, -0.0347, -0.0650, -0.6022,  0.0118,\n",
              "         -0.1354, -0.2929, -0.2084, -0.4902,  0.6500,  0.1685, -0.7105, -0.3890,\n",
              "          0.2476, -0.2165, -0.6606,  0.0412]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSTkll8so9aY",
        "outputId": "e5286f25-c685-4657-cc2a-21f8d5654c38"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.ReLU"
      ],
      "metadata": {
        "id": "X47bupm4pHQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-linear activations are what create the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce non linearlity, helping neural networks learn a wide variety phenomenal"
      ],
      "metadata": {
        "id": "X5L3Cd8KpQse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1} \\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykv5dsQ3p4ht",
        "outputId": "9bf06fd4-3a7b-4064-837a-fa133c5bca56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.2155, -0.4049, -0.8427,  0.1457, -0.0643, -0.4941, -0.4382, -0.1710,\n",
            "         -0.1029, -0.2099, -0.1976, -0.2963,  0.4958,  0.0162, -0.7350, -0.5259,\n",
            "          0.1827, -0.0915, -0.2880, -0.1483],\n",
            "        [ 0.2453, -0.3701, -0.7320,  0.3557,  0.1142, -0.1105, -0.5984, -0.2136,\n",
            "         -0.4932, -0.3136, -0.0386, -0.0660,  0.4938,  0.4970, -0.7241, -0.6247,\n",
            "         -0.0164, -0.1783, -0.4323,  0.0151],\n",
            "        [ 0.3137, -0.6424, -0.5849,  0.1244, -0.0347, -0.0650, -0.6022,  0.0118,\n",
            "         -0.1354, -0.2929, -0.2084, -0.4902,  0.6500,  0.1685, -0.7105, -0.3890,\n",
            "          0.2476, -0.2165, -0.6606,  0.0412]], grad_fn=<AddmmBackward0>) \n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.2155, 0.0000, 0.0000, 0.1457, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.4958, 0.0162, 0.0000, 0.0000, 0.1827, 0.0000,\n",
            "         0.0000, 0.0000],\n",
            "        [0.2453, 0.0000, 0.0000, 0.3557, 0.1142, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.4938, 0.4970, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0151],\n",
            "        [0.3137, 0.0000, 0.0000, 0.1244, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.6500, 0.1685, 0.0000, 0.0000, 0.2476, 0.0000,\n",
            "         0.0000, 0.0412]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU makes all negatives zero and outputs the same numbers for positive values"
      ],
      "metadata": {
        "id": "y8toDDN3qJDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Sequential"
      ],
      "metadata": {
        "id": "vI400aNgqnVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`nn.Sequential` is an ordered container of modules. The data is passed through all the modules in the same order as defined.\n",
        "\n",
        "You can use sequential containers to put together a quick network like `seq_modules``\n"
      ],
      "metadata": {
        "id": "TZvhF-NRqqIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpmJt-gQrV_9",
        "outputId": "7cfe8beb-2873-4af2-f429-353e34af419a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0787, -0.0265,  0.0381,  0.2250, -0.2706, -0.0462,  0.1415,  0.0530,\n",
              "          0.1138,  0.0839],\n",
              "        [-0.1836,  0.1150,  0.1064,  0.1978, -0.1172, -0.1620,  0.2105,  0.0848,\n",
              "          0.1421,  0.0098],\n",
              "        [-0.1120,  0.0866,  0.0424,  0.2905, -0.2480,  0.0116,  0.1444,  0.1412,\n",
              "          0.0400,  0.1570]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Softmax"
      ],
      "metadata": {
        "id": "djxsXt2jrjRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last linear layer of the netowrk returns logits - raw values in [-infty, infty] -  which are passed to the `nn.Softmax` module\n",
        "The logits are scaled to value[0,1] representing the model's predicted probabilities for each class. `dim`paramter indicates the dimension along which the value must sum to 1"
      ],
      "metadata": {
        "id": "nk3WRjwnsGJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQs0hKZ7wAPy",
        "outputId": "c4c5b0b7-de25-4164-cbb8-3c34940fb8a6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0787, -0.0265,  0.0381,  0.2250, -0.2706, -0.0462,  0.1415,  0.0530,\n",
              "          0.1138,  0.0839],\n",
              "        [-0.1836,  0.1150,  0.1064,  0.1978, -0.1172, -0.1620,  0.2105,  0.0848,\n",
              "          0.1421,  0.0098],\n",
              "        [-0.1120,  0.0866,  0.0424,  0.2905, -0.2480,  0.0116,  0.1444,  0.1412,\n",
              "          0.0400,  0.1570]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "pred_probab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juu46acfs3QZ",
        "outputId": "d8d20f62-bb44-40af-d4d5-ecb80c4c3d34"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0896, 0.0943, 0.1006, 0.1213, 0.0739, 0.0925, 0.1116, 0.1022, 0.1086,\n",
              "         0.1054],\n",
              "        [0.0792, 0.1067, 0.1058, 0.1160, 0.0846, 0.0809, 0.1174, 0.1036, 0.1097,\n",
              "         0.0961],\n",
              "        [0.0838, 0.1022, 0.0977, 0.1253, 0.0731, 0.0948, 0.1082, 0.1079, 0.0975,\n",
              "         0.1096]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.rand(size=(4, 4), dtype=torch.float32)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY8Tky71uQkZ",
        "outputId": "6fc57081-c676-4424-d61a-46c998708ac7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4821, 0.5069, 0.9276, 0.9228],\n",
              "        [0.3100, 0.3381, 0.6353, 0.9888],\n",
              "        [0.7175, 0.6312, 0.7221, 0.7960],\n",
              "        [0.0813, 0.0582, 0.2255, 0.9559]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input tensor of dimensions B x C, B = number of batches (rows), C = number of classes(columns).\n",
        "inputs = torch.rand(size=(4, 4), dtype=torch.float32)\n",
        "soft_dim0 = torch.softmax(inputs, dim=0)\n",
        "soft_dim1 = torch.softmax(inputs, dim=1)\n",
        "print('**** INPUTS ****')\n",
        "print(inputs)\n",
        "print('**** SOFTMAX DIM=0 ****')\n",
        "print(soft_dim0)\n",
        "print('**** SOFTMAX DIM=1 ****')\n",
        "print(soft_dim1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Wf62eMtWN7",
        "outputId": "8ee4acc5-d41d-4aca-9af7-285c3a55f56d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** INPUTS ****\n",
            "tensor([[0.8793, 0.8018, 0.7319, 0.3394],\n",
            "        [0.7831, 0.0488, 0.7002, 0.0189],\n",
            "        [0.3044, 0.9235, 0.8594, 0.8932],\n",
            "        [0.8315, 0.6727, 0.4078, 0.1659]])\n",
            "**** SOFTMAX DIM=0 ****\n",
            "tensor([[0.2920, 0.2874, 0.2612, 0.2322],\n",
            "        [0.2652, 0.1354, 0.2531, 0.1685],\n",
            "        [0.1644, 0.3246, 0.2967, 0.4040],\n",
            "        [0.2784, 0.2526, 0.1889, 0.1952]])\n",
            "**** SOFTMAX DIM=1 ****\n",
            "tensor([[0.2966, 0.2745, 0.2560, 0.1729],\n",
            "        [0.3489, 0.1674, 0.3212, 0.1625],\n",
            "        [0.1562, 0.2902, 0.2721, 0.2815],\n",
            "        [0.3309, 0.2823, 0.2166, 0.1701]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the softmax with dim=0, the sum of each column =1, while for dim=1, it is the sum of the rows that equals 1. Usually, you do not want to perform a softmax operation across the batch dimension."
      ],
      "metadata": {
        "id": "G82u8LFktcvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Parameters"
      ],
      "metadata": {
        "id": "gx2zkV8vwnhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "many layers inside a neural network are `parameterized - have associated weights and biases that ate optimizzed during training`\n",
        "\n",
        "subclassing `nn.Module` tracks all fields defined inside model object and makes all parameters accessible using your model's `parameters()` or `named_parameters()` methods"
      ],
      "metadata": {
        "id": "k4JF0Dovwsx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We iterate over each paramter, and print its size and a preview of its values"
      ],
      "metadata": {
        "id": "VIF0BzKMxl2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBwcU2pXxlZA",
        "outputId": "b7bfcd6f-5818-48ea-c3dc-136cb4b2b276"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0353, -0.0236,  0.0047,  ...,  0.0198, -0.0139, -0.0345],\n",
            "        [ 0.0017,  0.0104, -0.0141,  ..., -0.0288, -0.0204,  0.0223]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0134, 0.0138], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0013, -0.0069, -0.0213,  ..., -0.0232,  0.0332,  0.0096],\n",
            "        [-0.0141, -0.0440, -0.0296,  ..., -0.0038,  0.0418,  0.0141]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0023, 0.0021], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0428, -0.0099, -0.0288,  ...,  0.0156,  0.0382, -0.0392],\n",
            "        [ 0.0337, -0.0416,  0.0391,  ...,  0.0262, -0.0259,  0.0147]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0334, 0.0096], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}